<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Survey of Image genAI | Tristan Peat </title> <meta name="author" content="Tristan Peat"> <meta name="description" content="Survey of some recent papers on image generation models"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tpeat.github.io/blog/2023/diffusion/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tristan </span> Peat </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resume.pdf">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Survey of Image genAI</h1> <p class="post-meta"> December 01, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/cv"> <i class="fa-solid fa-hashtag fa-sm"></i> cv</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Last November, I attended a talk by Dr. Yang Song through ML@GT seminar series on Consistency Models. Inspired by his clear delivery and important research, I felt drawn towards exploring image generation more.</p> <p>Here are some papers I’ve read recently:</p> <h3 id="denoising-diffusion-probabilistic-models">Denoising Diffusion Probabilistic Models</h3> <p>In the landscape of generative artificial intelligence, Denoising Diffusion Probabilistic Models (DDPMs) stand out as a beacon of innovation, merging the worlds of machine learning and thermodynamics in a way that might just make you wonder if a crash course in non-equilibrium thermodynamics is in order. At its core, DDPM operates through a meticulously designed variational bound, which serves as a bridge connecting diffusion probabilistic models with denoising score matching and Langevin dynamics.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ddpm-480.webp 480w,/assets/img/ddpm-800.webp 800w,/assets/img/ddpm-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ddpm.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="understanding-the-mechanism">Understanding the Mechanism</h3> <p>DDPMs introduce a progressively lossy decompression scheme, utilizing autoregressive decoding to achieve remarkable results. The essence of diffusion models lies in their structure as parameterized Markov chains, trained through variational inference to master the art of reversing a diffusion process. This technique hinges on learning transitions within the chain, guiding the model to reverse engineer from a state of high entropy back to the original data distribution.</p> <p>One of the pivotal revelations in the study of diffusion models is their parameterization, revealing an equivalence with denoising score matching across multiple noise levels during the training phase. Although these models deliver exceptional sample quality, they encounter challenges with log likelihood when juxtaposed with likelihood-based models, leading researchers to analyze these dynamics through the prism of lossy compression.</p> <h3 id="the-math-behind-the-magic">The Math Behind the Magic</h3> <p>At the heart of diffusion models is a latent variable framework, encapsulated by the equation:</p> <p>’'’insert equation here’’’</p> <p>This equation symbolizes the averaging over all conceivable paths that latent variables could traverse, starting from the original data point and culminating in the learned distribution. The genesis of this journey begins at the “most diffused state,” a point where the data’s inherent structure has been obliterated.</p> <p>The Markov chain that defines the reverse process is a series of learned Gaussian transitions, embarking from a state of maximal entropy. The distinct nature of diffusion models stems from their approximation to the posterior, a fixed Markov chain known as the diffusion process, which incrementally introduces Gaussian noise into the data.</p> <h3 id="forward-pass-simplified">Forward Pass Simplified</h3> <p>Breaking down the forward pass, we see a methodical addition of Gaussian noise at each timestep, transitioning the data from its initial state towards increasing levels of diffusion. This process allows the model to navigate through a multidimensional noise landscape, with each dimension uniformly affected thanks to the identity matrix</p> <p>’'’insert code here’’’</p> <p>However, the real ingenuity emerges in the model’s ability to reparameterize, enabling a tractable closed-form sample through the clever manipulation of variance schedules. Whether adopting a fixed constant or a dynamic schedule, the choice of variance scheduling, from linear to cosine, significantly influences the model’s performance, with recent enhancements spotlighting the efficacy of cosine schedules.</p> <h3 id="reverse-diffusion-the-road-back">Reverse Diffusion: The Road Back</h3> <p>As the model approaches the end of its diffusion journey, the latent variable resembles an isotropic Gaussian, paving the way for the reverse diffusion process. This process involves approximating the less noisy state from a given noisy image, a task elegantly executed by neural networks trained to predict Gaussian parameters.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dog-diffusion-480.webp 480w,/assets/img/dog-diffusion-800.webp 800w,/assets/img/dog-diffusion-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/dog-diffusion.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="training-and-beyond">Training and Beyond</h3> <p>Training a DDPM draws parallels with the variational autoencoder (VAE), focusing on optimizing the negative log-likelihood of the training data. This endeavor touches upon concepts like variational lower bounds and Kullback-Leibler divergence, underscoring the intricate dance between achieving tractability and preserving the model’s flexibility to capture the rich structure of arbitrary data.</p> <h3 id="leveraging-physics-for-ai">Leveraging Physics for AI</h3> <p>Interestingly, DDPMs borrow heavily from physics, particularly non-equilibrium statistical physics, to refine their training methodologies. Techniques like Annealed Importance Sampling and Langevin dynamics offer a window into defining Gaussian diffusion processes with target distributions as equilibrium states, showcasing the profound interplay between physics and AI in advancing generative models.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/langevin-dynamics-480.webp 480w,/assets/img/langevin-dynamics-800.webp 800w,/assets/img/langevin-dynamics-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/langevin-dynamics.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="future-directions-and-challenges">Future Directions and Challenges</h3> <p>As we delve deeper into the nuances of DDPMs, questions of efficiency, sample quality, and computational demands come to the fore. The journey from abstract mathematical formulations to practical applications highlights both the potential and the hurdles in harnessing the full power of diffusion models for generative tasks.</p> <h3 id="conclusion">Conclusion</h3> <p>Denoising Diffusion Probabilistic Models represent a fascinating confluence of ideas, from the mathematical intricacies of variational inference to the thermodynamic principles guiding their operation. As we stand on the brink of new discoveries in generative AI, DDPMs offer a promising pathway, challenging us to rethink the boundaries of what’s possible in the realm of artificial intelligence.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/research/">Why I want to do research</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Tristan Peat. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>